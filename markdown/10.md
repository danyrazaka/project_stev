# 10. Automatisation et optimisation

L'automatisation et l'optimisation des processus représentent des leviers majeurs pour améliorer l'efficacité, la qualité et la rentabilité d'une usine de stevia, même à petite échelle. Dans le contexte malgache, où la contrainte de temps est importante et où l'utilisateur a mentionné son intérêt pour Python et le machine learning, cette section présente des solutions adaptées et progressives.

## 10.1 Systèmes de surveillance et contrôle

La mise en place de systèmes de surveillance et de contrôle constitue la première étape vers l'automatisation d'une unité de production de stevia.

### 10.1.1 Monitoring des paramètres critiques

**Paramètres agricoles à surveiller** :
- Humidité du sol (tensiomètres ou capteurs capacitifs)
- Conditions météorologiques locales (mini-stations météo)
- Stades de développement des plants (suivi phénologique)
- Apparition de maladies ou ravageurs (pièges connectés)

**Paramètres de transformation à contrôler** :
- Températures des différents procédés
- Débits et pressions des fluides
- pH et conductivité des extraits
- Temps de cycle des opérations
- Consommation énergétique

**Solutions adaptées à petite échelle** :
- Capteurs autonomes à faible coût (Arduino, ESP32)
- Systèmes d'acquisition de données simplifiés
- Interfaces utilisateur intuitives (tableaux de bord visuels)
- Alertes par SMS pour événements critiques

### 10.1.2 Automatisation progressive des processus

Pour une petite unité à Madagascar, une approche par niveaux est recommandée :

**Niveau 1 : Automatisation de base** :
- Contrôleurs de température PID simples
- Minuteries programmables pour cycles d'opération
- Vannes automatiques pour les fluides principaux
- Systèmes d'alarme pour conditions hors spécifications

**Niveau 2 : Automatisation intermédiaire** :
- Automates programmables industriels (API) compacts
- Interfaces homme-machine (IHM) tactiles
- Régulation en boucle fermée des paramètres critiques
- Enregistrement automatique des données de production

**Niveau 3 : Intégration avancée** :
- Système SCADA simplifié pour supervision globale
- Communication entre les différents équipements
- Recettes de fabrication programmables
- Rapports automatisés de production et qualité

### 10.1.3 Architecture système recommandée

Pour une implémentation réussie dans le contexte malgache :

**Architecture matérielle** :
- Contrôleurs robustes et résistants aux conditions tropicales
- Redondance des composants critiques
- Protection contre les variations électriques
- Possibilité de fonctionnement dégradé en mode manuel

**Architecture logicielle** :
- Systèmes modulaires évolutifs
- Interfaces multilingues (français, malgache)
- Sauvegarde locale des données
- Possibilité de diagnostic et support à distance

**Considérations pratiques** :
- Formation approfondie du personnel local
- Documentation technique simplifiée et visuelle
- Stock de pièces de rechange essentielles
- Contrats de maintenance avec fournisseurs régionaux

## 10.2 Scripts Python pour la simulation et l'optimisation des processus

L'utilisation de Python permet de développer des outils sur mesure pour simuler, optimiser et contrôler les différents aspects de la production de stevia.

### 10.2.1 Simulation de croissance et rendement

Le script suivant permet de simuler la croissance et le rendement de la stevia en fonction des conditions environnementales et des pratiques culturales :

```python
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime, timedelta

class SteviaGrowthSimulator:
    def __init__(self, start_date, region="Analamanga"):
        self.start_date = start_date
        self.region = region
        
        # Paramètres de base selon la région
        if region == "Analamanga":
            self.base_temp = 12  # Température de base pour la croissance
            self.optimal_temp = 25  # Température optimale
            self.max_temp = 35  # Température maximale supportée
            self.rainfall_factor = 0.8  # Facteur d'influence des précipitations
        elif region == "Itasy":
            self.base_temp = 13
            self.optimal_temp = 26
            self.max_temp = 36
            self.rainfall_factor = 0.9
        else:
            raise ValueError("Région non supportée")
        
        # Paramètres de culture
        self.planting_density = 80000  # plants/ha
        self.leaf_potential = 25  # g de feuilles sèches par plant à maturité
        self.glycoside_content = 0.12  # 12% de glycosides dans les feuilles
        
    def generate_weather_data(self, days=120):
        """Génère des données météo synthétiques basées sur les tendances saisonnières"""
        dates = [self.start_date + timedelta(days=i) for i in range(days)]
        
        # Tendances saisonnières simplifiées pour Madagascar
        month_temps = {
            1: (22, 30), 2: (22, 30), 3: (21, 29),  # Saison chaude et humide
            4: (19, 28), 5: (17, 26), 6: (15, 24),  # Transition
            7: (14, 23), 8: (14, 24), 9: (16, 26),  # Saison fraîche et sèche
            10: (18, 28), 11: (20, 29), 12: (21, 30)  # Transition et début saison chaude
        }
        
        month_rain = {
            1: 300, 2: 280, 3: 220,  # Saison des pluies
            4: 100, 5: 60, 6: 40,    # Transition
            7: 30, 8: 30, 9: 40,     # Saison sèche
            10: 80, 11: 150, 12: 250  # Début saison des pluies
        }
        
        # Génération des données avec variation aléatoire
        temps_min = []
        temps_max = []
        rainfall = []
        
        for date in dates:
            month = date.month
            base_min, base_max = month_temps[month]
            
            # Ajout de variation aléatoire
            temp_min = base_min + np.random.normal(0, 1.5)
            temp_max = base_max + np.random.normal(0, 2)
            
            # Précipitations avec distribution plus réaliste
            month_total = month_rain[month]
            day_rain = 0
            if np.random.random() < (month_total / 300) * 0.4:  # Probabilité de pluie
                day_rain = np.random.gamma(2, month_total/60)
            
            temps_min.append(temp_min)
            temps_max.append(temp_max)
            rainfall.append(day_rain)
        
        return {
            'dates': dates,
            'temp_min': temps_min,
            'temp_max': temps_max,
            'rainfall': rainfall
        }
    
    def calculate_growing_degree_days(self, weather_data):
        """Calcule les degrés-jours de croissance"""
        gdd = []
        for tmin, tmax in zip(weather_data['temp_min'], weather_data['temp_max']):
            tmean = (tmin + tmax) / 2
            daily_gdd = max(0, tmean - self.base_temp)
            # Ajustement pour températures supérieures à l'optimum
            if tmean > self.optimal_temp:
                reduction = (tmean - self.optimal_temp) / (self.max_temp - self.optimal_temp)
                daily_gdd *= max(0, 1 - reduction)
            gdd.append(daily_gdd)
        
        return gdd
    
    def simulate_growth(self, irrigation=True, fertilization_level=1.0, harvest_threshold=800):
        """Simule la croissance et le rendement de la stevia"""
        # Génération des données météo
        weather = self.generate_weather_data(days=150)
        
        # Calcul des degrés-jours
        gdd = self.calculate_growing_degree_days(weather)
        
        # Initialisation des variables de croissance
        cumulative_gdd = 0
        biomass = []
        water_stress = []
        growth_rate = []
        harvest_dates = []
        harvest_yields = []
        
        # Facteurs de stress
        for i, date in enumerate(weather['dates']):
            # Accumulation des degrés-jours
            cumulative_gdd += gdd[i]
            
            # Calcul du stress hydrique
            rain = weather['rainfall'][i]
            water_factor = 1.0
            if rain < 2 and not irrigation:
                # Stress hydrique progressif sans irrigation
                days_since_rain = min(i, 10)
                for j in range(1, min(i+1, 11)):
                    if weather['rainfall'][i-j] > 2:
                        days_since_rain = j
                        break
                water_factor = max(0.2, 1 - (days_since_rain * 0.08))
            
            # Taux de croissance journalier
            daily_growth = gdd[i] * water_factor * fertilization_level * 0.01
            growth_rate.append(daily_growth)
            water_stress.append(water_factor)
            
            # Biomasse cumulée (simplifiée)
            current_biomass = cumulative_gdd * water_factor * fertilization_level * 0.05
            biomass.append(current_biomass)
            
            # Vérification des conditions de récolte
            if cumulative_gdd >= harvest_threshold:
                harvest_dates.append(date)
                
                # Calcul du rendement à la récolte
                plant_yield = self.leaf_potential * (current_biomass / 100) * min(1.0, current_biomass / 80)
                ha_yield = (plant_yield * self.planting_density) / 1000  # kg/ha
                glycoside_yield = ha_yield * self.glycoside_content
                
                harvest_yields.append({
                    'date': date,
                    'leaf_yield_kg_ha': ha_yield,
                    'glycoside_kg_ha': glycoside_yield
                })
                
                # Réinitialisation après récolte
                cumulative_gdd = 0
                
        return {
            'weather': weather,
            'growth': {
                'biomass': biomass,
                'water_stress': water_stress,
                'growth_rate': growth_rate
            },
            'harvests': harvest_yields
        }
    
    def plot_results(self, results):
        """Visualise les résultats de la simulation"""
        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 15), sharex=True)
        
        # Données météo
        ax1.plot(results['weather']['dates'], results['weather']['temp_max'], 'r-', label='Temp. max')
        ax1.plot(results['weather']['dates'], results['weather']['temp_min'], 'b-', label='Temp. min')
        ax1.set_ylabel('Température (°C)')
        ax1.legend(loc='upper left')
        
        ax1_twin = ax1.twinx()
        ax1_twin.bar(results['weather']['dates'], results['weather']['rainfall'], 
                    alpha=0.3, color='blue', label='Précipitations')
        ax1_twin.set_ylabel('Précipitations (mm)')
        ax1_twin.legend(loc='upper right')
        
        # Croissance
        ax2.plot(results['weather']['dates'], results['growth']['biomass'], 'g-', label='Biomasse')
        ax2.set_ylabel('Biomasse relative')
        ax2.legend(loc='upper left')
        
        ax2_twin = ax2.twinx()
        ax2_twin.plot(results['weather']['dates'], results['growth']['water_stress'], 
                     'c--', label='Facteur hydrique')
        ax2_twin.set_ylabel('Facteur de stress (0-1)')
        ax2_twin.legend(loc='upper right')
        
        # Récoltes
        if results['harvests']:
            harvest_dates = [h['date'] for h in results['harvests']]
            leaf_yields = [h['leaf_yield_kg_ha'] for h in results['harvests']]
            glycoside_yields = [h['glycoside_kg_ha'] for h in results['harvests']]
            
            ax3.bar(harvest_dates, leaf_yields, width=5, label='Rendement feuilles (kg/ha)')
            ax3.set_ylabel('Rendement feuilles (kg/ha)')
            ax3.legend(loc='upper left')
            
            ax3_twin = ax3.twinx()
            ax3_twin.bar([d + timedelta(days=2) for d in harvest_dates], 
                        glycoside_yields, width=5, color='orange', 
                        label='Rendement glycosides (kg/ha)')
            ax3_twin.set_ylabel('Rendement glycosides (kg/ha)')
            ax3_twin.legend(loc='upper right')
        
        ax3.set_xlabel('Date')
        fig.autofmt_xdate()
        plt.tight_layout()
        plt.savefig('/home/ubuntu/projet_stevia/simulation_croissance_stevia.png')
        plt.close()
        
        return '/home/ubuntu/projet_stevia/simulation_croissance_stevia.png'

# Exemple d'utilisation
if __name__ == "__main__":
    # Simulation pour plantation en novembre à Analamanga
    start_date = datetime(2025, 11, 1)
    simulator = SteviaGrowthSimulator(start_date, region="Analamanga")
    
    # Comparaison de différentes stratégies
    scenarios = [
        {"name": "Optimal (irrigation + fertilisation optimale)", 
         "params": {"irrigation": True, "fertilization_level": 1.0}},
        {"name": "Sans irrigation", 
         "params": {"irrigation": False, "fertilization_level": 1.0}},
        {"name": "Fertilisation réduite", 
         "params": {"irrigation": True, "fertilization_level": 0.7}},
    ]
    
    for scenario in scenarios:
        print(f"\nScénario: {scenario['name']}")
        results = simulator.simulate_growth(**scenario['params'])
        
        # Affichage des résultats de récolte
        total_leaf_yield = 0
        total_glycoside_yield = 0
        
        print("Récoltes prévues:")
        for harvest in results['harvests']:
            print(f"  Date: {harvest['date'].strftime('%d/%m/%Y')}")
            print(f"  Rendement feuilles: {harvest['leaf_yield_kg_ha']:.1f} kg/ha")
            print(f"  Rendement glycosides: {harvest['glycoside_kg_ha']:.1f} kg/ha")
            print("")
            
            total_leaf_yield += harvest['leaf_yield_kg_ha']
            total_glycoside_yield += harvest['glycoside_kg_ha']
        
        print(f"Rendement annuel total en feuilles: {total_leaf_yield:.1f} kg/ha")
        print(f"Rendement annuel total en glycosides: {total_glycoside_yield:.1f} kg/ha")
        
        # Génération du graphique
        if scenario['name'] == "Optimal (irrigation + fertilisation optimale)":
            graph_path = simulator.plot_results(results)
            print(f"Graphique généré: {graph_path}")
```

Ce script permet de :
- Simuler la croissance de la stevia en fonction des conditions climatiques locales
- Évaluer l'impact de différentes stratégies d'irrigation et de fertilisation
- Prédire les dates optimales de récolte et les rendements attendus
- Visualiser graphiquement les résultats pour faciliter la prise de décision

### 10.2.2 Optimisation des processus d'extraction

Le script suivant permet d'optimiser les paramètres d'extraction pour maximiser le rendement et la qualité :

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score
import joblib
import os

class SteviaExtractionOptimizer:
    def __init__(self, data_path=None):
        self.model_yield = None
        self.model_quality = None
        self.scaler = StandardScaler()
        
        # Création de données synthétiques si aucun chemin n'est fourni
        if data_path and os.path.exists(data_path):
            self.data = pd.read_csv(data_path)
        else:
            print("Génération de données synthétiques pour démonstration...")
            self.generate_synthetic_data()
    
    def generate_synthetic_data(self, n_samples=100):
        """Génère des données synthétiques pour démontrer le fonctionnement"""
        np.random.seed(42)
        
        # Paramètres d'extraction
        temperature = np.random.uniform(50, 90, n_samples)
        time = np.random.uniform(20, 60, n_samples)
        ph = np.random.uniform(4.5, 7.5, n_samples)
        solvent_ratio = np.random.uniform(5, 15, n_samples)
        
        # Génération des résultats avec relations non-linéaires et bruit
        base_yield = (
            -0.02 * (temperature - 75)**2 + 
            0.01 * (time - 40)**2 + 
            -0.5 * (ph - 6)**2 + 
            0.2 * solvent_ratio
        )
        
        # Ajout d'interactions entre variables
        interactions = (
            0.01 * temperature * time / 100 +
            -0.02 * temperature * (ph - 6) +
            0.03 * time * solvent_ratio / 10
        )
        
        # Rendement final avec bruit
        extraction_yield = base_yield + interactions + 10 + np.random.normal(0, 1, n_samples)
        extraction_yield = np.clip(extraction_yield, 5, 20)  # Limites réalistes
        
        # Qualité (pureté) avec relations différentes
        base_quality = (
            -0.01 * (temperature - 65)**2 + 
            0.005 * time + 
            -0.8 * (ph - 5.5)**2 + 
            -0.1 * (solvent_ratio - 10)**2
        )
        
        quality_interactions = (
            -0.005 * temperature * (ph - 5.5) +
            0.002 * time * (ph - 5.5)
        )
        
        quality = base_quality + quality_interactions + 85 + np.random.normal(0, 2, n_samples)
        quality = np.clip(quality, 70, 98)  # Limites réalistes
        
        # Création du DataFrame
        self.data = pd.DataFrame({
            'temperature': temperature,
            'time': time,
            'ph': ph,
            'solvent_ratio': solvent_ratio,
            'extraction_yield': extraction_yield,
            'quality': quality
        })
    
    def train_models(self):
        """Entraîne des modèles de prédiction pour le rendement et la qualité"""
        # Préparation des données
        X = self.data[['temperature', 'time', 'ph', 'solvent_ratio']]
        y_yield = self.data['extraction_yield']
        y_quality = self.data['quality']
        
        # Normalisation
        X_scaled = self.scaler.fit_transform(X)
        
        # Division train/test
        X_train, X_test, y_yield_train, y_yield_test = train_test_split(
            X_scaled, y_yield, test_size=0.2, random_state=42)
        _, _, y_quality_train, y_quality_test = train_test_split(
            X_scaled, y_quality, test_size=0.2, random_state=42)
        
        # Entraînement du modèle pour le rendement
        param_grid = {
            'n_estimators': [50, 100, 200],
            'max_depth': [None, 10, 20],
            'min_samples_split': [2, 5, 10]
        }
        
        rf_yield = RandomForestRegressor(random_state=42)
        grid_search_yield = GridSearchCV(rf_yield, param_grid, cv=5, 
                                        scoring='neg_mean_squared_error')
        grid_search_yield.fit(X_train, y_yield_train)
        self.model_yield = grid_search_yield.best_estimator_
        
        # Entraînement du modèle pour la qualité
        rf_quality = RandomForestRegressor(random_state=42)
        grid_search_quality = GridSearchCV(rf_quality, param_grid, cv=5, 
                                          scoring='neg_mean_squared_error')
        grid_search_quality.fit(X_train, y_quality_train)
        self.model_quality = grid_search_quality.best_estimator_
        
        # Évaluation des modèles
        y_yield_pred = self.model_yield.predict(X_test)
        y_quality_pred = self.model_quality.predict(X_test)
        
        yield_rmse = np.sqrt(mean_squared_error(y_yield_test, y_yield_pred))
        yield_r2 = r2_score(y_yield_test, y_yield_pred)
        
        quality_rmse = np.sqrt(mean_squared_error(y_quality_test, y_quality_pred))
        quality_r2 = r2_score(y_quality_test, y_quality_pred)
        
        print(f"Modèle de rendement - RMSE: {yield_rmse:.2f}, R²: {yield_r2:.2f}")
        print(f"Modèle de qualité - RMSE: {quality_rmse:.2f}, R²: {quality_r2:.2f}")
        
        # Sauvegarde des modèles
        joblib.dump(self.model_yield, '/home/ubuntu/projet_stevia/model_yield.pkl')
        joblib.dump(self.model_quality, '/home/ubuntu/projet_stevia/model_quality.pkl')
        joblib.dump(self.scaler, '/home/ubuntu/projet_stevia/scaler.pkl')
        
        return {
            'yield_rmse': yield_rmse,
            'yield_r2': yield_r2,
            'quality_rmse': quality_rmse,
            'quality_r2': quality_r2
        }
    
    def optimize_parameters(self, target_quality=90, weight_yield=0.7, weight_quality=0.3):
        """Trouve les paramètres optimaux pour maximiser le rendement avec une qualité minimale"""
        if self.model_yield is None or self.model_quality is None:
            self.train_models()
        
        # Grille de paramètres à explorer
        n_samples = 10000
        param_grid = {
            'temperature': np.random.uniform(50, 90, n_samples),
            'time': np.random.uniform(20, 60, n_samples),
            'ph': np.random.uniform(4.5, 7.5, n_samples),
            'solvent_ratio': np.random.uniform(5, 15, n_samples)
        }
        
        param_df = pd.DataFrame(param_grid)
        X_grid_scaled = self.scaler.transform(param_df)
        
        # Prédictions
        yield_pred = self.model_yield.predict(X_grid_scaled)
        quality_pred = self.model_quality.predict(X_grid_scaled)
        
        # Normalisation des prédictions pour la fonction objectif
        yield_norm = (yield_pred - yield_pred.min()) / (yield_pred.max() - yield_pred.min())
        quality_norm = (quality_pred - quality_pred.min()) / (quality_pred.max() - quality_pred.min())
        
        # Fonction objectif combinée
        objective = weight_yield * yield_norm + weight_quality * quality_norm
        
        # Filtrage par qualité minimale
        quality_mask = quality_pred >= target_quality
        
        if np.sum(quality_mask) > 0:
            # Sélection des paramètres optimaux parmi ceux qui respectent la qualité minimale
            filtered_objective = objective.copy()
            filtered_objective[~quality_mask] = -np.inf
            best_idx = np.argmax(filtered_objective)
            
            best_params = {
                'temperature': param_grid['temperature'][best_idx],
                'time': param_grid['time'][best_idx],
                'ph': param_grid['ph'][best_idx],
                'solvent_ratio': param_grid['solvent_ratio'][best_idx]
            }
            
            predicted_yield = yield_pred[best_idx]
            predicted_quality = quality_pred[best_idx]
            
            print(f"\nParamètres optimaux pour qualité ≥ {target_quality}%:")
            print(f"  Température: {best_params['temperature']:.1f}°C")
            print(f"  Temps d'extraction: {best_params['time']:.1f} minutes")
            print(f"  pH: {best_params['ph']:.2f}")
            print(f"  Ratio solvant/matière: {best_params['solvent_ratio']:.1f}")
            print(f"\nPerformances prédites:")
            print(f"  Rendement d'extraction: {predicted_yield:.2f}%")
            print(f"  Qualité (pureté): {predicted_quality:.2f}%")
            
            return {
                'parameters': best_params,
                'predicted_yield': predicted_yield,
                'predicted_quality': predicted_quality
            }
        else:
            print(f"Aucune combinaison ne permet d'atteindre la qualité minimale de {target_quality}%")
            print("Essayez avec une valeur cible de qualité plus basse")
            return None
    
    def plot_parameter_effects(self):
        """Visualise l'effet des différents paramètres sur le rendement et la qualité"""
        if self.model_yield is None or self.model_quality is None:
            self.train_models()
        
        # Valeurs de référence (moyennes)
        ref_params = {
            'temperature': 70,
            'time': 40,
            'ph': 6.0,
            'solvent_ratio': 10
        }
        
        # Plages de variation pour chaque paramètre
        ranges = {
            'temperature': np.linspace(50, 90, 50),
            'time': np.linspace(20, 60, 50),
            'ph': np.linspace(4.5, 7.5, 50),
            'solvent_ratio': np.linspace(5, 15, 50)
        }
        
        fig, axs = plt.subplots(2, 2, figsize=(15, 12))
        axs = axs.flatten()
        
        for i, param in enumerate(ref_params.keys()):
            # Création d'un jeu de données où seul le paramètre actuel varie
            X_test = []
            for value in ranges[param]:
                test_point = ref_params.copy()
                test_point[param] = value
                X_test.append([test_point['temperature'], test_point['time'], 
                              test_point['ph'], test_point['solvent_ratio']])
            
            X_test = np.array(X_test)
            X_test_scaled = self.scaler.transform(X_test)
            
            # Prédictions
            yield_pred = self.model_yield.predict(X_test_scaled)
            quality_pred = self.model_quality.predict(X_test_scaled)
            
            # Tracé
            ax = axs[i]
            ax.plot(ranges[param], yield_pred, 'b-', label='Rendement (%)')
            ax.set_xlabel(param)
            ax.set_ylabel('Rendement (%)', color='b')
            ax.tick_params(axis='y', labelcolor='b')
            
            ax2 = ax.twinx()
            ax2.plot(ranges[param], quality_pred, 'r-', label='Qualité (%)')
            ax2.set_ylabel('Qualité (%)', color='r')
            ax2.tick_params(axis='y', labelcolor='r')
            
            ax.set_title(f'Effet de {param}')
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('/home/ubuntu/projet_stevia/parametres_extraction.png')
        plt.close()
        
        return '/home/ubuntu/projet_stevia/parametres_extraction.png'

# Exemple d'utilisation
if __name__ == "__main__":
    optimizer = SteviaExtractionOptimizer()
    optimizer.train_models()
    
    # Optimisation pour différents niveaux de qualité
    for quality_target in [85, 90, 95]:
        print(f"\n{'='*50}")
        print(f"Optimisation pour qualité cible: {quality_target}%")
        optimizer.optimize_parameters(target_quality=quality_target)
    
    # Visualisation de l'effet des paramètres
    graph_path = optimizer.plot_parameter_effects()
    print(f"\nGraphique généré: {graph_path}")
```

Ce script permet de :
- Modéliser la relation entre les paramètres d'extraction et les résultats (rendement, qualité)
- Optimiser les paramètres pour maximiser le rendement tout en maintenant une qualité minimale
- Visualiser l'effet de chaque paramètre sur les performances
- Fournir des recommandations précises pour les opérateurs

### 10.2.3 Système de contrôle de la qualité

Le script suivant implémente un système de contrôle qualité basé sur l'analyse d'image pour la détection des défauts dans les feuilles de stevia :

```python
import cv2
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
import os
import pandas as pd
from sklearn.cluster import KMeans

class SteviaLeafQualityAnalyzer:
    def __init__(self, image_dir='/home/ubuntu/projet_stevia/images'):
        self.image_dir = image_dir
        os.makedirs(image_dir, exist_ok=True)
        
        # Paramètres de qualité
        self.color_thresholds = {
            'good': {'lower': np.array([35, 50, 50]), 'upper': np.array([85, 255, 255])},
            'yellow': {'lower': np.array([20, 50, 50]), 'upper': np.array([35, 255, 255])},
            'brown': {'lower': np.array([0, 50, 20]), 'upper': np.array([20, 200, 100])}
        }
        
        # Historique des analyses
        self.history = []
    
    def analyze_image(self, image_path, save_result=True):
        """Analyse une image de feuilles de stevia pour évaluer la qualité"""
        # Chargement de l'image
        image = cv2.imread(image_path)
        if image is None:
            print(f"Erreur: Impossible de charger l'image {image_path}")
            return None
        
        # Conversion en HSV pour meilleure analyse des couleurs
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        
        # Création des masques pour différentes conditions
        masks = {}
        for condition, threshold in self.color_thresholds.items():
            masks[condition] = cv2.inRange(hsv, threshold['lower'], threshold['upper'])
        
        # Analyse des proportions
        total_pixels = image.shape[0] * image.shape[1]
        proportions = {}
        for condition, mask in masks.items():
            proportions[condition] = cv2.countNonZero(mask) / total_pixels * 100
        
        # Détection des contours pour analyse de forme
        leaf_mask = masks['good'] + masks['yellow']  # Combine good and yellow areas
        contours, _ = cv2.findContours(leaf_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # Filtrage des contours par taille
        min_contour_area = 500  # Ajuster selon la résolution de l'image
        valid_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_contour_area]
        
        # Analyse des défauts
        defects = []
        for cnt in valid_contours:
            # Création d'un masque pour ce contour spécifique
            leaf_mask = np.zeros_like(masks['good'])
            cv2.drawContours(leaf_mask, [cnt], 0, 255, -1)
            
            # Intersection avec le masque des zones brunes
            defect_mask = cv2.bitwise_and(masks['brown'], leaf_mask)
            defect_ratio = cv2.countNonZero(defect_mask) / max(1, cv2.countNonZero(leaf_mask)) * 100
            
            if defect_ratio > 5:  # Seuil de défaut significatif
                defects.append({
                    'area': cv2.contourArea(cnt),
                    'defect_ratio': defect_ratio
                })
        
        # Calcul du score de qualité global (0-100)
        quality_score = 100 - (proportions.get('yellow', 0) * 0.5 + proportions.get('brown', 0) * 2)
        quality_score = max(0, min(100, quality_score))
        
        # Classification de la qualité
        if quality_score >= 90:
            quality_class = "Excellente"
        elif quality_score >= 75:
            quality_class = "Bonne"
        elif quality_score >= 60:
            quality_class = "Moyenne"
        else:
            quality_class = "Faible"
        
        # Résultats
        results = {
            'image_path': image_path,
            'date': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'color_proportions': proportions,
            'defects_count': len(defects),
            'quality_score': quality_score,
            'quality_class': quality_class
        }
        
        # Ajout à l'historique
        self.history.append(results)
        
        # Visualisation des résultats
        if save_result:
            self._visualize_results(image, masks, results)
        
        return results
    
    def _visualize_results(self, image, masks, results):
        """Crée une visualisation des résultats d'analyse"""
        # Création d'une image de visualisation
        vis_image = image.copy()
        
        # Superposition des masques avec des couleurs différentes
        green_mask = cv2.bitwise_and(image, image, mask=masks['good'])
        yellow_mask = np.zeros_like(image)
        yellow_mask[masks['yellow'] > 0] = [0, 255, 255]  # Jaune en BGR
        brown_mask = np.zeros_like(image)
        brown_mask[masks['brown'] > 0] = [0, 0, 255]  # Rouge en BGR
        
        # Combinaison des masques
        alpha = 0.5
        cv2.addWeighted(green_mask, alpha, vis_image, 1 - alpha, 0, vis_image)
        cv2.addWeighted(yellow_mask, alpha, vis_image, 1 - alpha, 0, vis_image)
        cv2.addWeighted(brown_mask, alpha, vis_image, 1 - alpha, 0, vis_image)
        
        # Ajout des informations textuelles
        font = cv2.FONT_HERSHEY_SIMPLEX
        cv2.putText(vis_image, f"Score: {results['quality_score']:.1f}", 
                   (10, 30), font, 1, (255, 255, 255), 2)
        cv2.putText(vis_image, f"Qualité: {results['quality_class']}", 
                   (10, 70), font, 1, (255, 255, 255), 2)
        
        # Enregistrement de l'image
        base_name = os.path.basename(results['image_path'])
        output_path = os.path.join(self.image_dir, f"analyzed_{base_name}")
        cv2.imwrite(output_path, vis_image)
        
        # Création d'un graphique des proportions
        plt.figure(figsize=(10, 6))
        
        # Graphique en barres des proportions
        categories = list(results['color_proportions'].keys())
        values = list(results['color_proportions'].values())
        colors = ['green', 'yellow', 'brown']
        
        plt.bar(categories, values, color=colors)
        plt.title('Analyse de la qualité des feuilles de stevia')
        plt.ylabel('Proportion (%)')
        plt.ylim(0, 100)
        
        # Ajout du score de qualité
        plt.text(0.5, 0.9, f"Score de qualité: {results['quality_score']:.1f}/100", 
                horizontalalignment='center', transform=plt.gca().transAxes, 
                fontsize=14, bbox=dict(facecolor='white', alpha=0.8))
        
        # Enregistrement du graphique
        chart_path = os.path.join(self.image_dir, f"chart_{base_name.split('.')[0]}.png")
        plt.savefig(chart_path)
        plt.close()
        
        return output_path, chart_path
    
    def generate_report(self, output_path='/home/ubuntu/projet_stevia/rapport_qualite.csv'):
        """Génère un rapport CSV des analyses effectuées"""
        if not self.history:
            print("Aucune analyse à inclure dans le rapport")
            return None
        
        # Préparation des données
        report_data = []
        for analysis in self.history:
            row = {
                'date': analysis['date'],
                'image': os.path.basename(analysis['image_path']),
                'score': analysis['quality_score'],
                'classe': analysis['quality_class'],
                'defauts': analysis['defects_count']
            }
            
            # Ajout des proportions de couleur
            for color, prop in analysis['color_proportions'].items():
                row[f'prop_{color}'] = prop
            
            report_data.append(row)
        
        # Création du DataFrame et export
        df = pd.DataFrame(report_data)
        df.to_csv(output_path, index=False)
        
        print(f"Rapport généré: {output_path}")
        return output_path
    
    def analyze_batch(self, image_folder, pattern='*.jpg'):
        """Analyse un lot d'images dans un dossier"""
        import glob
        
        # Recherche des images correspondant au pattern
        image_paths = glob.glob(os.path.join(image_folder, pattern))
        
        if not image_paths:
            print(f"Aucune image trouvée avec le pattern {pattern} dans {image_folder}")
            return []
        
        results = []
        for img_path in image_paths:
            print(f"Analyse de {os.path.basename(img_path)}...")
            result = self.analyze_image(img_path)
            if result:
                results.append(result)
        
        # Génération du rapport
        self.generate_report()
        
        return results

# Exemple d'utilisation (commenté car nécessite des images réelles)
"""
if __name__ == "__main__":
    analyzer = SteviaLeafQualityAnalyzer()
    
    # Analyse d'une seule image
    result = analyzer.analyze_image('/chemin/vers/image_test.jpg')
    print(f"Score de qualité: {result['quality_score']:.1f}")
    print(f"Classe de qualité: {result['quality_class']}")
    
    # Analyse d'un lot d'images
    batch_results = analyzer.analyze_batch('/dossier/images')
    
    # Génération du rapport
    report_path = analyzer.generate_report()
"""
```

Ce script permet de :
- Analyser automatiquement la qualité des feuilles de stevia par traitement d'image
- Détecter les défauts (jaunissement, brunissement, taches)
- Quantifier la proportion de feuilles de différentes qualités
- Générer des rapports visuels et statistiques
- Suivre l'évolution de la qualité dans le temps

## 10.3 Applications de machine learning pour l'amélioration continue

Au-delà des scripts spécifiques, le machine learning peut être appliqué à divers aspects de la production de stevia pour une amélioration continue.

### 10.3.1 Prédiction de rendement et planification

**Applications potentielles** :
- Prédiction des rendements en fonction des données historiques et météorologiques
- Optimisation du calendrier de plantation et de récolte
- Détection précoce des anomalies de croissance
- Planification des ressources (main-d'œuvre, équipements)

**Données nécessaires** :
- Historique des rendements par parcelle
- Données météorologiques locales
- Pratiques culturales appliquées
- Caractéristiques des sols

**Mise en œuvre progressive** :
1. Collecte structurée des données de base (tableurs, formulaires mobiles)
2. Développement de modèles simples (régression, arbres de décision)
3. Intégration dans un tableau de bord de décision
4. Raffinement continu avec l'accumulation de données

### 10.3.2 Contrôle qualité automatisé

**Applications potentielles** :
- Analyse d'images pour la détection des maladies et ravageurs
- Classification automatique des feuilles selon leur qualité
- Prédiction de la teneur en glycosides à partir de caractéristiques visuelles
- Détection des anomalies dans les paramètres de production

**Technologies adaptées** :
- Vision par ordinateur sur smartphones (applications dédiées)
- Capteurs low-cost connectés (Arduino, Raspberry Pi)
- Modèles légers exécutables localement (sans connexion internet)
- Interfaces utilisateur simplifiées pour les opérateurs

### 10.3.3 Optimisation de la chaîne de production

**Applications potentielles** :
- Optimisation des paramètres de séchage en fonction des conditions ambiantes
- Ajustement automatique des recettes d'extraction
- Prédiction de la qualité finale à partir des paramètres intermédiaires
- Détection des dérives de processus

**Approche recommandée** :
- Commencer par des modèles simples basés sur des règles
- Évoluer vers des modèles statistiques à mesure que les données s'accumulent
- Intégrer progressivement des boucles de rétroaction automatisées
- Former le personnel à l'interprétation et à l'utilisation des prédictions

## 10.4 Technologies d'automatisation adaptées à l'échelle du projet

Pour une usine de stevia à petite échelle à Madagascar, l'automatisation doit être adaptée aux contraintes locales tout en apportant des bénéfices tangibles.

### 10.4.1 Solutions d'automatisation frugale

**Principes directeurs** :
- Robustesse et simplicité plutôt que sophistication
- Facilité de maintenance avec ressources locales
- Évolutivité progressive
- Résilience face aux coupures électriques et connectivité limitée

**Technologies recommandées** :
- Contrôleurs Arduino/ESP32 pour l'automatisation de base
- Capteurs low-cost avec redondance
- Interfaces utilisateur sur tablettes Android
- Systèmes de stockage d'énergie (batteries, panneaux solaires)

**Exemples d'applications** :
- Contrôle automatisé de l'irrigation basé sur l'humidité du sol
- Régulation de température des séchoirs avec alertes SMS
- Suivi des stocks et traçabilité par codes QR
- Collecte de données via formulaires mobiles

### 10.4.2 Intégration des technologies mobiles

Les smartphones et tablettes représentent des outils puissants et accessibles pour l'automatisation à petite échelle :

**Applications mobiles dédiées** :
- Saisie des données de production sur le terrain
- Capture et analyse d'images pour le contrôle qualité
- Suivi des opérations et maintenance
- Formation du personnel via tutoriels visuels

**Avantages dans le contexte malgache** :
- Matériel largement disponible et familier
- Coût d'acquisition modéré
- Fonctionnement sur batterie
- Possibilité de travail hors ligne avec synchronisation ultérieure

**Exemple d'architecture** :
- Applications Android développées avec Flutter/React Native
- Base de données locale SQLite
- Synchronisation avec serveur central quand la connexion est disponible
- Interfaces multilingues (français, malgache)

### 10.4.3 Tableau de bord de gestion intégrée

Un tableau de bord centralisé permet de visualiser et d'optimiser l'ensemble des opérations :

**Fonctionnalités clés** :
- Suivi en temps réel des indicateurs de performance
- Visualisation des tendances et détection d'anomalies
- Planification des opérations et allocation des ressources
- Traçabilité complète de la production

**Mise en œuvre technique** :
- Application web responsive (accessible sur ordinateur et mobile)
- Développement avec frameworks légers (Flask, Bootstrap)
- Visualisations interactives (Plotly, D3.js)
- Hébergement local sur serveur dédié avec UPS

**Exemple de code pour un tableau de bord simple** :

```python
from flask import Flask, render_template, jsonify, request
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import json
import os
import sqlite3
from datetime import datetime, timedelta
import random  # Pour la démonstration uniquement

app = Flask(__name__)

# Configuration de la base de données
DB_PATH = '/home/ubuntu/projet_stevia/stevia_production.db'

def init_db():
    """Initialise la base de données si elle n'existe pas"""
    if not os.path.exists(DB_PATH):
        conn = sqlite3.connect(DB_PATH)
        c = conn.cursor()
        
        # Création des tables
        c.execute('''
        CREATE TABLE production_data (
            id INTEGER PRIMARY KEY,
            date TEXT,
            batch_id TEXT,
            field_id TEXT,
            harvest_weight REAL,
            dry_weight REAL,
            moisture_content REAL,
            quality_score REAL
        )
        ''')
        
        c.execute('''
        CREATE TABLE extraction_data (
            id INTEGER PRIMARY KEY,
            date TEXT,
            batch_id TEXT,
            temperature REAL,
            time REAL,
            ph REAL,
            solvent_ratio REAL,
            yield_percent REAL,
            purity_percent REAL
        )
        ''')
        
        c.execute('''
        CREATE TABLE inventory (
            id INTEGER PRIMARY KEY,
            date TEXT,
            product_type TEXT,
            quantity REAL,
            unit TEXT
        )
        ''')
        
        # Génération de données de démonstration
        generate_demo_data(conn)
        
        conn.commit()
        conn.close()

def generate_demo_data(conn):
    """Génère des données de démonstration"""
    c = conn.cursor()
    
    # Données de production
    start_date = datetime.now() - timedelta(days=90)
    for i in range(90):
        date = (start_date + timedelta(days=i)).strftime('%Y-%m-%d')
        
        # Simulation de 1-3 lots par jour
        for j in range(random.randint(1, 3)):
            batch_id = f"B{date.replace('-', '')}-{j+1}"
            field_id = f"F{random.randint(1, 5)}"
            
            # Valeurs avec tendances saisonnières et variations aléatoires
            base_harvest = 100 + 20 * np.sin(i/15)  # Variation saisonnière
            harvest_weight = max(50, base_harvest + random.normalvariate(0, 15))
            
            moisture_content = random.uniform(65, 80)
            dry_weight = harvest_weight * (1 - moisture_content/100)
            
            quality_score = random.normalvariate(85, 8)
            quality_score = max(50, min(100, quality_score))
            
            c.execute('''
            INSERT INTO production_data 
            (date, batch_id, field_id, harvest_weight, dry_weight, moisture_content, quality_score)
            VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (date, batch_id, field_id, harvest_weight, dry_weight, moisture_content, quality_score))
    
    # Données d'extraction
    for i in range(45):  # Moins de lots d'extraction que de récolte
        date = (start_date + timedelta(days=i*2)).strftime('%Y-%m-%d')
        batch_id = f"E{date.replace('-', '')}"
        
        temperature = random.uniform(65, 80)
        extraction_time = random.uniform(30, 50)
        ph = random.uniform(5.0, 7.0)
        solvent_ratio = random.uniform(8, 12)
        
        # Rendement et pureté basés sur les paramètres
        base_yield = 12 - 0.1 * abs(temperature - 72) - 0.05 * abs(extraction_time - 40) - 0.5 * abs(ph - 6)
        yield_percent = max(5, min(18, base_yield + random.normalvariate(0, 1.5)))
        
        base_purity = 90 - 0.2 * abs(temperature - 70) - 0.1 * abs(extraction_time - 35) - 1 * abs(ph - 5.5)
        purity_percent = max(75, min(98, base_purity + random.normalvariate(0, 2)))
        
        c.execute('''
        INSERT INTO extraction_data 
        (date, batch_id, temperature, time, ph, solvent_ratio, yield_percent, purity_percent)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (date, batch_id, temperature, extraction_time, ph, solvent_ratio, yield_percent, purity_percent))
    
    # Données d'inventaire
    products = [
        ("Feuilles fraîches", "kg"),
        ("Feuilles séchées", "kg"),
        ("Extrait brut", "L"),
        ("Poudre de stevia", "kg")
    ]
    
    for i in range(90):
        date = (start_date + timedelta(days=i)).strftime('%Y-%m-%d')
        
        for product, unit in products:
            # Simulation de production et consommation
            if product == "Feuilles fraîches":
                base_qty = 80 + 20 * np.sin(i/15)
                quantity = max(0, base_qty + random.normalvariate(0, 15))
            elif product == "Feuilles séchées":
                base_qty = 20 + 5 * np.sin(i/15)
                quantity = max(0, base_qty + random.normalvariate(0, 4))
            elif product == "Extrait brut":
                base_qty = 15 + 3 * np.sin(i/15)
                quantity = max(0, base_qty + random.normalvariate(0, 3))
            else:  # Poudre
                base_qty = 5 + 1 * np.sin(i/15)
                quantity = max(0, base_qty + random.normalvariate(0, 1))
            
            c.execute('''
            INSERT INTO inventory 
            (date, product_type, quantity, unit)
            VALUES (?, ?, ?, ?)
            ''', (date, product, quantity, unit))

@app.route('/')
def index():
    """Page d'accueil du tableau de bord"""
    return render_template('index.html')

@app.route('/api/production_summary')
def production_summary():
    """Résumé des données de production"""
    conn = sqlite3.connect(DB_PATH)
    
    # Données de production par jour
    df_prod = pd.read_sql_query('''
    SELECT date, SUM(harvest_weight) as total_harvest, 
           SUM(dry_weight) as total_dry, AVG(quality_score) as avg_quality
    FROM production_data
    GROUP BY date
    ORDER BY date
    ''', conn)
    
    # Données d'extraction
    df_extract = pd.read_sql_query('''
    SELECT date, AVG(yield_percent) as avg_yield, 
           AVG(purity_percent) as avg_purity
    FROM extraction_data
    GROUP BY date
    ORDER BY date
    ''', conn)
    
    # Inventaire actuel
    df_inventory = pd.read_sql_query('''
    SELECT product_type, quantity, unit
    FROM inventory
    WHERE date = (SELECT MAX(date) FROM inventory)
    ''', conn)
    
    conn.close()
    
    # Création des graphiques
    fig_harvest = px.line(df_prod, x='date', y=['total_harvest', 'total_dry'], 
                         title='Production journalière (kg)')
    
    fig_quality = px.line(df_prod, x='date', y='avg_quality', 
                         title='Qualité moyenne des feuilles')
    fig_quality.update_layout(yaxis_range=[50, 100])
    
    fig_extraction = px.line(df_extract, x='date', y=['avg_yield', 'avg_purity'], 
                            title='Performance d\'extraction')
    
    # Conversion en JSON pour le template
    charts = {
        'harvest': json.loads(fig_harvest.to_json()),
        'quality': json.loads(fig_quality.to_json()),
        'extraction': json.loads(fig_extraction.to_json())
    }
    
    inventory = df_inventory.to_dict('records')
    
    return jsonify({
        'charts': charts,
        'inventory': inventory
    })

@app.route('/api/process_optimization')
def process_optimization():
    """Recommandations d'optimisation des processus"""
    conn = sqlite3.connect(DB_PATH)
    
    # Analyse des paramètres d'extraction et résultats
    df_extract = pd.read_sql_query('''
    SELECT temperature, time, ph, solvent_ratio, yield_percent, purity_percent
    FROM extraction_data
    ''', conn)
    
    conn.close()
    
    # Identification des paramètres optimaux (approche simplifiée)
    # Pour un modèle réel, utiliser les scripts d'optimisation présentés précédemment
    
    # Meilleurs lots pour rendement
    best_yield = df_extract.sort_values('yield_percent', ascending=False).head(5)
    
    # Meilleurs lots pour pureté
    best_purity = df_extract.sort_values('purity_percent', ascending=False).head(5)
    
    # Meilleurs lots pour compromis rendement/pureté
    df_extract['combined_score'] = df_extract['yield_percent'] * 0.4 + df_extract['purity_percent'] * 0.6
    best_combined = df_extract.sort_values('combined_score', ascending=False).head(5)
    
    # Calcul des paramètres moyens pour les meilleurs lots
    optimal_params = {
        'yield': {
            'temperature': best_yield['temperature'].mean(),
            'time': best_yield['time'].mean(),
            'ph': best_yield['ph'].mean(),
            'solvent_ratio': best_yield['solvent_ratio'].mean(),
            'expected_yield': best_yield['yield_percent'].mean(),
            'expected_purity': best_yield['purity_percent'].mean()
        },
        'purity': {
            'temperature': best_purity['temperature'].mean(),
            'time': best_purity['time'].mean(),
            'ph': best_purity['ph'].mean(),
            'solvent_ratio': best_purity['solvent_ratio'].mean(),
            'expected_yield': best_purity['yield_percent'].mean(),
            'expected_purity': best_purity['purity_percent'].mean()
        },
        'balanced': {
            'temperature': best_combined['temperature'].mean(),
            'time': best_combined['time'].mean(),
            'ph': best_combined['ph'].mean(),
            'solvent_ratio': best_combined['solvent_ratio'].mean(),
            'expected_yield': best_combined['yield_percent'].mean(),
            'expected_purity': best_combined['purity_percent'].mean()
        }
    }
    
    return jsonify(optimal_params)

if __name__ == '__main__':
    init_db()
    app.run(host='0.0.0.0', port=5000, debug=True)
```

En mettant en œuvre ces solutions d'automatisation et d'optimisation adaptées au contexte malgache, une petite usine de stevia peut significativement améliorer sa productivité, sa qualité et sa rentabilité, tout en minimisant les risques opérationnels et en facilitant la prise de décision.
